{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sirishaallarapu/AdvancedPySpark-/blob/main/Day5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6g8NmgaEU5c0",
        "outputId": "32c9df2b-6a5e-43b4-c7ed-90f6d03e3529"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------+\n",
            "| text|uppercase_text|\n",
            "+-----+--------------+\n",
            "|hello|         HELLO|\n",
            "|world|         WORLD|\n",
            "+-----+--------------+\n",
            "\n",
            "+------+--------+\n",
            "|number|is_prime|\n",
            "+------+--------+\n",
            "|     2|    true|\n",
            "|     4|   false|\n",
            "|     7|    true|\n",
            "|     9|   false|\n",
            "|    11|    true|\n",
            "+------+--------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import StringType, BooleanType\n",
        "\n",
        "spark = SparkSession.builder.appName(\"SparkUDFExample\").getOrCreate()\n",
        "\n",
        "def to_uppercase(s):\n",
        "    return s.upper() if s else None\n",
        "\n",
        "uppercase_udf = udf(to_uppercase, StringType())\n",
        "\n",
        "def is_prime(n):\n",
        "    if n is None or n < 2:\n",
        "        return False\n",
        "    for i in range(2, int(n ** 0.5) + 1):\n",
        "        if n % i == 0:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "is_prime_udf = udf(is_prime, BooleanType())\n",
        "\n",
        "df1 = spark.createDataFrame([(\"hello\",), (\"world\",)], [\"text\"])\n",
        "df1 = df1.withColumn(\"uppercase_text\", uppercase_udf(df1[\"text\"]))\n",
        "df1.show()\n",
        "\n",
        "df2 = spark.createDataFrame([(2,), (4,), (7,), (9,), (11,)], [\"number\"])\n",
        "df2 = df2.withColumn(\"is_prime\", is_prime_udf(df2[\"number\"]))\n",
        "df2.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, expr\n",
        "from pyspark.sql.types import StringType, BooleanType\n",
        "\n",
        "spark = SparkSession.builder.appName(\"Spark4Features\").getOrCreate()\n",
        "\n",
        "df1 = spark.range(5)\n",
        "df1.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3exKCp6KVFxr",
        "outputId": "4a4dfbe6-fa42-45f9-c7d4-1ec8dd649f58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+\n",
            "| id|\n",
            "+---+\n",
            "|  0|\n",
            "|  1|\n",
            "|  2|\n",
            "|  3|\n",
            "|  4|\n",
            "+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = spark.createDataFrame([(\"10\",), (\"abc\",)], [\"value\"])\n",
        "df2.selectExpr(\"CAST(value AS INT)\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w38R-Y9FV7sJ",
        "outputId": "14e45d5b-05e0-4060-f818-b83725e28ddf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+\n",
            "|value|\n",
            "+-----+\n",
            "|   10|\n",
            "| NULL|\n",
            "+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = spark.readStream.format(\"rate\").option(\"rowsPerSecond\", 1).load()\n",
        "df3.selectExpr(\"timestamp\", \"value\", \"value % 2 as is_even\").writeStream.format(\"console\").start()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoFJaE2sV_Gv",
        "outputId": "2d68b8c3-0d95-496e-c343-32a5246a67a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.streaming.query.StreamingQuery at 0x7f927babc1d0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df4 = spark.createDataFrame([(\"Zimmy\",), (\"Snoopi\",), (\"puffy\",)], [\"name\"])\n",
        "df4.orderBy(col(\"name\").asc()).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUy1a0i4Yn6E",
        "outputId": "48a5ce6f-17e9-4d02-e9e9-82eb7c94a111"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+\n",
            "|  name|\n",
            "+------+\n",
            "|Snoopi|\n",
            "| Zimmy|\n",
            "| puffy|\n",
            "+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, expr\n",
        "\n",
        "spark = SparkSession.builder.appName(\"Spark4Features\").getOrCreate()\n",
        "\n",
        "df5 = spark.createDataFrame([({\"key\": \"value\"},), ({\"number\": 10},)], [\"data\"])\n",
        "df5.withColumn(\"data_as_string\", expr(\"CAST(data AS STRING)\")).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlON17TwcLJW",
        "outputId": "c0beedf7-d723-4694-f5c5-50fbcf809035"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+--------------+\n",
            "|          data|data_as_string|\n",
            "+--------------+--------------+\n",
            "|{key -> value}|{key -> value}|\n",
            "|{number -> 10}|{number -> 10}|\n",
            "+--------------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df6 = spark.createDataFrame([(\"hello\",), (\"world\",)], [\"text\"])\n",
        "df6.selectExpr(\"upper(text)\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1DIXzN7coSE",
        "outputId": "863e4cad-6c38-40a4-d30b-eb8477bebf61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+\n",
            "|upper(text)|\n",
            "+-----------+\n",
            "|      HELLO|\n",
            "|      WORLD|\n",
            "+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df7 = spark.sql(\"SELECT 'Spark 4.0' AS version\")\n",
        "df7.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtqKzC1lcsXr",
        "outputId": "e410cc48-1b55-4bfe-f7fb-5440c65ba82e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|  version|\n",
            "+---------+\n",
            "|Spark 4.0|\n",
            "+---------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}